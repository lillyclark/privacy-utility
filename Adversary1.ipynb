{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two strategies for clustering user data points (time, location) into user ID bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import os\n",
    "\n",
    "import scipy.io\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import sys, os\n",
    "import itertools\n",
    "import numpy\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in matlab data - this takes a while and about 2gb memory\n",
      "Done loading matlab data.\n"
     ]
    }
   ],
   "source": [
    "matlab_filename = 'realitymining.mat'\n",
    "print(\"Loading in matlab data - this takes a while and about 2gb memory\")\n",
    "matlab_obj = scipy.io.loadmat(matlab_filename)\n",
    "print(\"Done loading matlab data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validSubjects(allSubjects):\n",
    "    return [s for s in allSubjects if hasNumeric(s,'mac') and hasNumeric(s,'my_hashedNumber')]\n",
    "\n",
    "\n",
    "# idDicts: subjects -> {int: subject}, {float: (int, subject)}, {int: (int, subject)}\n",
    "# First hash is contiguousId: subjectObject\n",
    "# second hash is macAddress: contiguousId, subjectObject\n",
    "# third hash is hashedNumber: contiguousId, subjectObject\n",
    "# because the id dictionaries reference the subject object, we can replace\n",
    "# the array of subject objects with these dictionaries.\n",
    "\n",
    "def idDicts(subjects):\n",
    "    return (dict((i, s) for (i,s) in enumerate(subjects)),\n",
    "        dict((getNumeric(s,'mac'), (i, s)) for (i,s) in enumerate(subjects)),\n",
    "        dict((getNumeric(s, 'my_hashedNumber'), (i, s)) for (i,s) in enumerate(subjects)))\n",
    "\n",
    "def hasNumeric(obj, field):\n",
    "    try:\n",
    "        obj[field][0][0]\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def getNumeric(obj, field):\n",
    "    return obj[field][0][0]\n",
    "\n",
    "def hasArray(obj, field):\n",
    "    try:\n",
    "        obj[field][0]\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def getArray(obj, field):\n",
    "    return obj[field][0]\n",
    "\n",
    "def convertDatetime(dt):\n",
    "    return datetime.fromordinal(int(dt)) + timedelta(days=dt%1) - timedelta(days=366) - timedelta(hours=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting valid subjects and creating id dictionaries.\n"
     ]
    }
   ],
   "source": [
    "print('Extracting valid subjects and creating id dictionaries.')\n",
    "subjects = validSubjects(matlab_obj['s'][0])\n",
    "idDictionaries = idDicts(subjects)\n",
    "idDict, macDict, hashNumDict = idDictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime, area.cell -> userID\n",
    "adversaryData = []\n",
    "\n",
    "for subjectID, subject in idDict.items():\n",
    "    if hasArray(subject, 'locs'):\n",
    "        for event in subject['locs']:\n",
    "            try:\n",
    "                timeplace = list(event)\n",
    "#                 time = convertDatetime(timeplace[0])\n",
    "                time = timeplace[0]\n",
    "                place = timeplace[1]\n",
    "                # assumes two people aren't texting at the exact same time from the same place\n",
    "                if place != 0.0:\n",
    "                    adversaryData.append([time, place, subjectID])\n",
    "            except:\n",
    "                pass\n",
    "adversaryData = np.array(adversaryData)\n",
    "\n",
    "adversaryData = adversaryData[adversaryData[:,0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversaryData = adversaryData[0:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy 1: \n",
    "An LSTM network (one for each of 90 users). \n",
    "1. The input to each LSTM is the (time, location) of the current data point, and the history of that user [(t1, l1), (t2, l2), etc]. \n",
    "2. The output is a likelihood that the current data point belongs to that user. \n",
    "3. The outputs of each user LSTM is argmaxed to determine the most likely user. \n",
    "4. The loss function compares the predicted user to the actual user. \n",
    "5. The weights of every user LSTM is adjusted based on the loss function. \n",
    "6. The datapoint is added to the history of the user it belongs to. \n",
    "7. Repeat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy 2: A (maybe) smarter approach.\n",
    "1. Assume the first data point of each user is known.\n",
    "2. For each new data point, for each user, the liklihood that this datapoint belongs to that user is a combination of: a) is it plausible based on the user's most recent location? b) is it plausible based on where this user usually visits?\n",
    "3. Assign the datapoint to the most likely user.\n",
    "4. At the end, compare the user bins to the true bins. Iterate over different equations for a & b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlocallikelihood(user, u, point, offset):\n",
    "    lastpoint = user[u][-1]\n",
    "    deltaloc = abs(point[1] - lastpoint[1])\n",
    "    deltatime = point[0] - lastpoint[0]\n",
    "    if deltatime == 0 or deltaloc == 0:\n",
    "        return 0\n",
    "    return (-deltaloc+offset/deltatime)\n",
    "\n",
    "def getgloballikelihood(user, u, point):\n",
    "    if len(user[u]) == 1:\n",
    "        return point[1] == user[u][0][1]\n",
    "    count_same_loc = (user[u][:,1] == point[1]).sum()\n",
    "    return count_same_loc/len(user[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_classify(adversaryData):\n",
    "    trueuser = {}\n",
    "    for point in adversaryData:\n",
    "        if point[2] in trueuser.keys():\n",
    "            trueuser[point[2]] = np.vstack([trueuser[point[2]], point])\n",
    "        else:\n",
    "            trueuser[point[2]] = point\n",
    "    return trueuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(threshold, offset, weight_l1, weight_l2):\n",
    "    num_users = 90\n",
    "    user = {}\n",
    "    user[0] = [adversaryData[0]]\n",
    "\n",
    "    for point in adversaryData[1:]:\n",
    "        uservec = np.zeros(len(user))\n",
    "        for u in user.keys():\n",
    "            l1 = getlocallikelihood(user, u, point, offset)\n",
    "            l2 = getgloballikelihood(user, u, point)\n",
    "            l = (weight_l1*l1+weight_l2*l2)/(weight_l1+weight_l2)\n",
    "            uservec[u] = l\n",
    "        if max(uservec) > threshold or len(uservec) >= num_users:\n",
    "            guess = np.argmax(uservec)\n",
    "            user[np.argmax(uservec)] = np.vstack([user[guess], point])\n",
    "        else:\n",
    "            user[max(user.keys())+1] = [point]\n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(user, trueuser):\n",
    "    u_count = []\n",
    "    \n",
    "    # lose points for inconsistently binned results\n",
    "    loss1 = 0\n",
    "    for u in user:\n",
    "        if len(user[u]) != 1:\n",
    "            (values,counts) = np.unique(user[u][:,2],return_counts=True)\n",
    "            ind=np.argmax(counts)\n",
    "            loss1 += (sum(counts) - counts[ind])\n",
    "            u_count.append(values[ind])\n",
    "    loss1 = loss1/len(adversaryData)\n",
    "    \n",
    "    # lose points for the wrong number of bins\n",
    "    loss2 = (len(user)-len(trueuser))/90\n",
    "    if loss2 < 0:\n",
    "        loss2 = -2*loss2\n",
    "    \n",
    "    # lose points for bins that are redundant\n",
    "    (us, counts) = np.unique(u_count, return_counts=True)\n",
    "    loss3 = sum(counts - np.ones(len(counts)))/sum(counts)\n",
    "    \n",
    "    return 4*loss1 + loss2 + loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printuserdict(outputuser):\n",
    "    print(\"User Dictionary\")\n",
    "    for u in outputuser:\n",
    "        if len(outputuser[u]) > 1:\n",
    "            (values,counts) = np.unique(outputuser[u][:,2],return_counts=True)\n",
    "            ind=np.argmax(counts)\n",
    "            print(u, values, len(outputuser[u]))\n",
    "        else:\n",
    "            print(u, outputuser[u][0][2], len(outputuser[u]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.01 1 1 0.6231111111111112\n",
      "User Dictionary\n",
      "0 [87.] 3\n",
      "1 [67.] 627\n",
      "2 [67.] 225\n",
      "3 [67.] 10\n",
      "4 [41.] 140\n",
      "5 [41. 85.] 17\n",
      "6 [41.] 14\n",
      "7 [85.] 435\n",
      "8 [85.] 529\n",
      "0.01 0.1 1 1 0.6179047619047618\n",
      "User Dictionary\n",
      "0 [87.] 3\n",
      "1 [67.] 256\n",
      "2 [67.] 599\n",
      "3 [67.] 7\n",
      "4 [41. 85.] 238\n",
      "5 [85.] 536\n",
      "6 [85.] 361\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "trueuser = true_classify(adversaryData)\n",
    "best_loss = 100\n",
    "for threshold in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    for offset in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        for weight_l1 in [1]:\n",
    "            for weight_l2 in [1]:\n",
    "# for threshold in [0.1]:\n",
    "#     for offset in [100]:\n",
    "#         for weight_l1 in [1]:\n",
    "#             for weight_l2 in [1]:\n",
    "                user = classify(threshold, offset, weight_l1, weight_l2)\n",
    "                loss = get_loss(user, trueuser)\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    print(threshold, offset, weight_l1, weight_l2, loss)\n",
    "                    outputuser = user\n",
    "                    printuserdict(outputuser)\n",
    "                    \n",
    "print(\"done\")\n",
    "# os.system('spd-say \"yee\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.0 3\n",
      "67.0 862\n",
      "41.0 160\n",
      "85.0 975\n"
     ]
    }
   ],
   "source": [
    "for u in trueuser:\n",
    "    print(u, len(trueuser[u]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
